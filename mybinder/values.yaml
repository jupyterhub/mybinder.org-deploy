binderhub:

  replicas: 2
  pdb:
    minAvailable: 1

  networkPolicy:
    enabled: true
    egress:
      tcpPorts:
        - 80 # http
        - 443 # https
        - 9418 # git
        - 873 # rsync
        - 1094 # xroot
      cidr: 0.0.0.0/0
  extraConfig:
    # Add banned repositories to the list below
    # They should be strings that will match "^<org-name>/<repo-name>.*"
    bans: |
      c.GitHubRepoProvider.banned_specs = [
        # e.g. '^org/repo.*',
        '^ines/spacy-binder.*',
        '^soft4voip/rak.*',
      ]
  service:
    type: ClusterIP

  cors: &cors
    allowOrigin: "*"

  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
    https:
      enabled: true
      type: "kube-lego"

  registry:
    enabled: true

  dind:
    enabled: true


  imageCleaner:
    enabled: true
    # when 80% of inodes are used,
    # cull images until only 40% are used.
    imageGCThresholdHigh: 80
    imageGCThresholdLow: 40
    host:
      enabled: false

  extraFooterScripts:
    00-matomo-tracking: |
      // Only load Matomo if DNT is not set.
      // This respects user preferences, and gives us a full score on uBlock origin
      if (navigator.doNotTrack != "1" && // Most Firefox & Chrome
        window.doNotTrack != "1" && // IE & Safari
        navigator.msDoNotTrack != "1" // Old IE
      ) {
      console.log("Loading Matomo tracking, since Do Not Track is off");
        var _paq = _paq || [];
        /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
        _paq.push(['trackPageView']);
        (function() {
          var u="//" + window.location.hostname + "/matomo/";
          _paq.push(['setTrackerUrl', u+'piwik.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
        })();
      }


  jupyterhub:
    cull:
      # cull every 11 minutes so it is out of phase
      # with the proxy check-routes interval of five minutes
      every: 660
      timeout: 600
      # maxAge is 6 hours: 6 * 3600 = 21600
      maxAge: 21600
    hub:
      networkPolicy:
        enabled: true
      pdb:
        minAvailable: 0
      extraConfigMap:
        cors: *cors
      extraConfig:
        neverRestart: |
          c.KubeSpawner.extra_pod_config.update({'restart_policy': 'Never'})
    proxy:
      networkPolicy:
        enabled: true
      pdb:
        minAvailable: 0
      service:
        type: ClusterIP
      chp:
        cmd:
          - configurable-http-proxy
          - --ip=0.0.0.0
          - --port=8000
          - --api-ip=0.0.0.0
          - --api-port=8001
          - --default-target=http://$(HUB_SERVICE_HOST):$(HUB_SERVICE_PORT)
          - --error-target=http://$(HUB_SERVICE_HOST):$(HUB_SERVICE_PORT)/hub/error
          - --log-level=error
    ingress:
      enabled: true
      annotations:
        ingress.kubernetes.io/proxy-body-size: 64m
        kubernetes.io/ingress.class: nginx
        kubernetes.io/tls-acme: "true"
    scheduling:
      userScheduler:
        enabled: true
        replicas: 2
    singleuser:
      networkPolicy:
        enabled: true
        egress: []

      initContainers:
      - name: tc-init
        image: minrk/tc-init:0.0.4
        env:
          - name: WHITELIST_CIDR
            value: 10.0.0.0/8
          - name: EGRESS_BANDWIDTH
            value: 1mbit
        securityContext:
          # capabilities.add seems to be disabled
          # by the `runAsUser: 1000` in the pod-level securityContext
          # unless we explicitly run as root
          runAsUser: 0
          capabilities:
            add:
            - NET_ADMIN
      schedulerStrategy: pack
      extraEnv:
        CULL_CONNECTED: '1'
        CULL_TIMEOUT: '600'
        CULL_KERNEL_TIMEOUT: '600'
        CULL_INTERVAL: '60'
  build:
    repo2dockerImage: jupyter/repo2docker:a161b09
    appendix: |
      USER root
      ENV BINDER_URL={binder_url}
      ENV REPO_URL={repo_url}
      RUN cd /tmp \
       && wget -q https://github.com/jupyterhub/mybinder.org-deploy/archive/ce31915cfc76b749a4e089b7c105856cea545319.tar.gz -O appendix.tar.gz \
       && tar --wildcards -xzf appendix.tar.gz --strip 1 */appendix \
       && ./appendix/run-appendix \
       && rm -rf appendix.tar.gz appendix
      USER $NB_USER
  perRepoQuota: 100

playground:
  image:
    name: yuvipanda/play.nteract.io
    tag: v0.2
  replicas: 1

nginx-ingress:
  rbac:
    create: true
  defaultBackend:
    minAvailable: 0
  statsExporter:
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "10254"
  controller:
    replicaCount: 5
    scope:
      enabled: true
    config:
      # Allow POSTs of upto 64MB, for large notebook support.
      proxy-body-size: 64m
    stats:
      enabled: true
    metrics:
      enabled: true
      service:
        annotations:
          prometheus.io/scrape: "true"
          prometheus.io/port: "10254"
    service:
      # Preserve client IPs
      externalTrafficPolicy: Local

redirector:
  nodeSelector: {}
  redirects: []

static:
  paths:
    - /badge.svg

kube-lego:
  config:
    LEGO_EMAIL: yuvipanda@gmail.com
    LEGO_URL: https://acme-v01.api.letsencrypt.org/directory
  rbac:
    create: true

grafana:
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      kubernetes.io/tls-acme: "true"
  persistence:
    enabled: true
    accessModes:
      - ReadWriteOnce

  grafana.ini:
    auth.anonymous:
      enabled: true
      org_name: Main Org.
      org_role: Viewer
    auth.basic:
      enabled: true
    smtp:
      enabled: true

prometheus:
  nodeExporter:
    updateStrategy:
      type: RollingUpdate
  alertmanager:
    enabled: false
  pushgateway:
    enabled: false
  rbac:
    create: true
  server:
    ingress:
      enabled: true
      annotations:
        kubernetes.io/ingress.class: nginx
        kubernetes.io/tls-acme: "true"

proxyPatches:
  nodeSelector: {}
  enabled: true
  interval: 60
  routes:
    "/user": "service:proxy-patches"

matomo:
  enabled: true
  nodeSelector: {}
  resources: {}
  replicas: 1
  service:
    type: ClusterIP
  db:
    username: matomo
    name: matomo
    tables_prefix: matomo_
